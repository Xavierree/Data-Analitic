{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xavierree/Data-Analitic/blob/Efficient_net/1_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LTtnkjwB9Zsv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTtnkjwB9Zsv",
        "outputId": "acba8535-07d7-43a9-e51b-77c13690a19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.9)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.0.15)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python-headless \"numpy<2.0\" pandas matplotlib albumentations tqdm scikit-learn torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34c18cb",
      "metadata": {
        "id": "c34c18cb"
      },
      "outputs": [],
      "source": [
        "# Instalasi dependensi dari requirements.txt\n",
        "\n",
        "# Impor pustaka dasar yang akan digunakan di beberapa sel\n",
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import albumentations as A\n",
        "from xml.etree import ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d338e19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d338e19",
        "outputId": "89fcc660-81b9-40e2-cdcf-f53b7ed23f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Mengunduh dataset dari Google Drive (ID: 1sky3FSRpfCbsBWQ_EtyTMZt1DipOsLm1)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1sky3FSRpfCbsBWQ_EtyTMZt1DipOsLm1\n",
            "From (redirected): https://drive.google.com/uc?id=1sky3FSRpfCbsBWQ_EtyTMZt1DipOsLm1&confirm=t&uuid=215a401a-20a8-45ca-bac7-bfe048d3b9be\n",
            "To: /content/dataset.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57.1M/57.1M [00:00<00:00, 106MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Unduhan selesai. Mengekstrak file 'dataset.zip'...\n",
            "‚úÖ Ekstraksi selesai.\n",
            "\n",
            "üìÇ Mengecek direktori sumber di: Gabungan\n",
            "üëç Direktori 'Image' dan 'Annotation' ditemukan. Memulai proses...\n",
            "\n",
            "‚öôÔ∏è Memproses data latih...\n",
            "‚ö†Ô∏è Peringatan: Anotasi 'immature-107_jpg.rf.e6c1dbeaacc81094cc0c733ccf439233(1).xml' tidak ditemukan, gambar 'immature-107_jpg.rf.e6c1dbeaacc81094cc0c733ccf439233(1).jpg' dilewati.\n",
            "\n",
            "‚öôÔ∏è Memproses data validasi...\n",
            "\n",
            "--- Ringkasan ---\n",
            "Total gambar latih: 1295\n",
            "Total gambar validasi: 325\n",
            "\n",
            "‚úÖ Pemisahan data selesai. Data disimpan di folder: 'data_split'\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Instalasi dan Impor Library Awal ---\n",
        "!pip install -q gdown\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import gdown\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 2. Konfigurasi Download (Bagian yang Perlu Diedit) ---\n",
        "FILE_ID = \"1sky3FSRpfCbsBWQ_EtyTMZt1DipOsLm1\"\n",
        "EXTRACTED_FOLDER_NAME = \"Gabungan\"\n",
        "\n",
        "# --- 3. Proses Download dan Ekstrak ---\n",
        "ZIP_FILE = \"dataset.zip\"\n",
        "print(f\"üì• Mengunduh dataset dari Google Drive (ID: {FILE_ID})...\")\n",
        "gdown.download(id=FILE_ID, output=ZIP_FILE, quiet=False)\n",
        "\n",
        "print(f\"\\n‚ú® Unduhan selesai. Mengekstrak file '{ZIP_FILE}'...\")\n",
        "with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "print(\"‚úÖ Ekstraksi selesai.\")\n",
        "\n",
        "# --- 4. Konfigurasi Path dan Pemisahan Data ---\n",
        "DATASET_DIR = EXTRACTED_FOLDER_NAME\n",
        "IMAGE_DIR_NAME = \"Image\"\n",
        "ANNOT_DIR_NAME = \"Annotation\"\n",
        "OUTPUT_DIR = \"data_split\"\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "IMAGE_DIR = os.path.join(DATASET_DIR, IMAGE_DIR_NAME)\n",
        "ANNOT_DIR = os.path.join(DATASET_DIR, ANNOT_DIR_NAME)\n",
        "\n",
        "print(f\"\\nüìÇ Mengecek direktori sumber di: {DATASET_DIR}\")\n",
        "\n",
        "if os.path.exists(IMAGE_DIR) and os.path.exists(ANNOT_DIR):\n",
        "    print(\"üëç Direktori 'Image' dan 'Annotation' ditemukan. Memulai proses...\")\n",
        "\n",
        "    TRAIN_IMG_DIR = os.path.join(OUTPUT_DIR, \"train\", \"Image\")\n",
        "    TRAIN_ANNOT_DIR = os.path.join(OUTPUT_DIR, \"train\", \"Annotation\")\n",
        "    VAL_IMG_DIR = os.path.join(OUTPUT_DIR, \"val\", \"Image\")\n",
        "    VAL_ANNOT_DIR = os.path.join(OUTPUT_DIR, \"val\", \"Annotation\")\n",
        "\n",
        "    os.makedirs(TRAIN_IMG_DIR, exist_ok=True)\n",
        "    os.makedirs(TRAIN_ANNOT_DIR, exist_ok=True)\n",
        "    os.makedirs(VAL_IMG_DIR, exist_ok=True)\n",
        "    os.makedirs(VAL_ANNOT_DIR, exist_ok=True)\n",
        "\n",
        "    image_filenames = [f for f in os.listdir(IMAGE_DIR) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "    train_images, val_images = train_test_split(image_filenames, train_size=TRAIN_RATIO, random_state=42)\n",
        "\n",
        "    def copy_files(file_list, src_img, src_annot, dst_img, dst_annot):\n",
        "        copied_count = 0\n",
        "        for filename in file_list:\n",
        "            annot_filename = os.path.splitext(filename)[0] + \".xml\"\n",
        "            src_annot_path = os.path.join(src_annot, annot_filename)\n",
        "\n",
        "            if os.path.exists(src_annot_path):\n",
        "                shutil.copy(os.path.join(src_img, filename), os.path.join(dst_img, filename))\n",
        "                shutil.copy(src_annot_path, os.path.join(dst_annot, annot_filename))\n",
        "                copied_count += 1\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Peringatan: Anotasi '{annot_filename}' tidak ditemukan, gambar '{filename}' dilewati.\")\n",
        "        return copied_count\n",
        "\n",
        "    print(\"\\n‚öôÔ∏è Memproses data latih...\")\n",
        "    num_train = copy_files(train_images, IMAGE_DIR, ANNOT_DIR, TRAIN_IMG_DIR, TRAIN_ANNOT_DIR)\n",
        "\n",
        "    print(\"\\n‚öôÔ∏è Memproses data validasi...\")\n",
        "    num_val = copy_files(val_images, IMAGE_DIR, ANNOT_DIR, VAL_IMG_DIR, VAL_ANNOT_DIR)\n",
        "\n",
        "    print(\"\\n--- Ringkasan ---\")\n",
        "    print(f\"Total gambar latih: {num_train}\")\n",
        "    print(f\"Total gambar validasi: {num_val}\")\n",
        "    print(f\"\\n‚úÖ Pemisahan data selesai. Data disimpan di folder: '{OUTPUT_DIR}'\")\n",
        "else:\n",
        "    print(f\"‚ùå Direktori data sumber tidak ditemukan di '{IMAGE_DIR}' atau '{ANNOT_DIR}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pqU0whjJtc_L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqU0whjJtc_L",
        "outputId": "c813b6f2-2c68-4a6e-d8d9-6d472d76be35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Konfigurasi dimuat.\n",
            "--------------------\n",
            "Device yang digunakan: cuda\n",
            "Jumlah Epoch: 20\n",
            "Ukuran Batch: 8\n",
            "Jumlah Kelas: 4 -> ['__background__', 'Immature', 'Mature', 'Normal']\n",
            "Output akan disimpan di: outputs\n",
            "Path data latih: data_split/train/Image\n",
            "Path data validasi: data_split/val/Image\n"
          ]
        }
      ],
      "source": [
        "# --- Impor Library untuk Konfigurasi ---\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# --- Konfigurasi Parameter Training ---\n",
        "BATCH_SIZE = 8\n",
        "RESIZE_TO = 640\n",
        "NUM_EPOCHS = 20\n",
        "# Untuk Colab, disarankan menggunakan 2 workers untuk menghindari potensi error\n",
        "NUM_WORKERS = 2\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# --- Konfigurasi Path Data ---\n",
        "# Path ini sudah benar menunjuk ke folder 'data_split' yang dibuat oleh sel sebelumnya.\n",
        "TRAIN_IMG = 'data_split/train/Image'\n",
        "TRAIN_ANNOT = 'data_split/train/Annotation'\n",
        "VALID_IMG = 'data_split/val/Image'\n",
        "VALID_ANNOT = 'data_split/val/Annotation'\n",
        "\n",
        "# --- Konfigurasi Kelas dan Direktori Output ---\n",
        "CLASSES = ['__background__', 'Immature', 'Mature', 'Normal']\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "OUT_DIR = 'outputs'\n",
        "\n",
        "# Membuat direktori output jika belum ada\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- Verifikasi Konfigurasi ---\n",
        "print(f\"Konfigurasi dimuat.\")\n",
        "print(\"--------------------\")\n",
        "print(f\"Device yang digunakan: {DEVICE}\")\n",
        "print(f\"Jumlah Epoch: {NUM_EPOCHS}\")\n",
        "print(f\"Ukuran Batch: {BATCH_SIZE}\")\n",
        "print(f\"Jumlah Kelas: {NUM_CLASSES} -> {CLASSES}\")\n",
        "print(f\"Output akan disimpan di: {OUT_DIR}\")\n",
        "print(f\"Path data latih: {TRAIN_IMG}\")\n",
        "print(f\"Path data validasi: {VALID_IMG}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1d85b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e1d85b9",
        "outputId": "18bbb228-e14b-4249-c508-22fe4f1ccd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fungsi utilitas ('custom_utils.py') berhasil didefinisikan.\n"
          ]
        }
      ],
      "source": [
        "# --- Cell 4: custom_utils.py ---\n",
        "\n",
        "class Averager:\n",
        "    def __init__(self): self.reset()\n",
        "    def send(self, value): self.current_total += value; self.iterations += 1\n",
        "    @property\n",
        "    def value(self): return self.current_total / self.iterations if self.iterations > 0 else 0\n",
        "    def reset(self): self.current_total = 0.0; self.iterations = 0.0\n",
        "\n",
        "class SaveBestModel:\n",
        "    def __init__(self, best_valid_map=0.0): self.best_valid_map = best_valid_map\n",
        "    def __call__(self, model, current_valid_map, epoch, out_dir):\n",
        "        if current_valid_map > self.best_valid_map:\n",
        "            self.best_valid_map = current_valid_map\n",
        "            file_name = f\"{out_dir}/best_model_mAP_{current_valid_map:.4f}.pth\"\n",
        "            print(f\"\\nValid mAP meningkat. Menyimpan model ke {file_name}\")\n",
        "            torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict()}, file_name)\n",
        "\n",
        "def get_train_transform():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5), A.RandomBrightnessContrast(p=0.3), A.Blur(blur_limit=3, p=0.1),\n",
        "        ToTensorV2(p=1.0)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "\n",
        "def get_valid_transform():\n",
        "    return A.Compose([ToTensorV2(p=1.0)], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "\n",
        "def save_loss_plot(out_dir, train_loss_list):\n",
        "    plt.figure(figsize=(10, 7)); plt.plot(train_loss_list, label='Train Loss')\n",
        "    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.title(\"Training Loss Plot\"); plt.legend()\n",
        "    plt.savefig(f\"{out_dir}/train_loss.png\"); plt.close()\n",
        "\n",
        "def save_mAP(out_dir, map_50_list, map_95_list):\n",
        "    plt.figure(figsize=(10, 7)); plt.plot(map_50_list, label='mAP@0.5', color='orange')\n",
        "    plt.plot(map_95_list, label='mAP@0.5:0.95', color='red'); plt.xlabel('Epochs')\n",
        "    plt.ylabel('mAP'); plt.title('mAP Over Epochs'); plt.legend()\n",
        "    plt.savefig(f\"{out_dir}/map_plot.png\"); plt.close()\n",
        "\n",
        "print(\"‚úÖ Fungsi utilitas ('custom_utils.py') berhasil didefinisikan.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c189add",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c189add",
        "outputId": "c1bee887-e67e-44a1-e618-8b7cf541cc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Kelas Dataset ('datasets.py') berhasil didefinisikan.\n"
          ]
        }
      ],
      "source": [
        "# --- Cell 5: datasets.py ---\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path, annot_path, width, height, classes, transforms=None):\n",
        "        self.img_path, self.annot_path = img_path, annot_path\n",
        "        self.width, self.height = width, height\n",
        "        self.classes, self.transforms = classes, transforms\n",
        "        self.all_images = sorted(glob.glob(os.path.join(img_path, \"*.jpg\")))\n",
        "    def __len__(self): return len(self.all_images)\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = os.path.basename(self.all_images[idx])\n",
        "        annot_path = os.path.join(self.annot_path, image_name.replace('.jpg', '.xml'))\n",
        "        image = cv2.imread(self.all_images[idx])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "\n",
        "        tree = ET.parse(annot_path)\n",
        "        root = tree.getroot()\n",
        "        boxes, labels = [], []\n",
        "        for obj in root.findall(\"object\"):\n",
        "            label = self.classes.index(obj.find(\"name\").text)\n",
        "            bndbox = obj.find(\"bndbox\")\n",
        "            xmin, ymin, xmax, ymax = map(int, [bndbox.find(tag).text for tag in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]])\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            labels.append(label)\n",
        "\n",
        "        # Buat dictionary target\n",
        "        target = {}\n",
        "\n",
        "        # Lakukan transformasi jika ada\n",
        "        if self.transforms:\n",
        "            # Konversi ke NumPy array SEBELUM augmentasi (INI PERBAIKANNYA)\n",
        "            sample = self.transforms(\n",
        "                image=image,\n",
        "                bboxes=boxes,\n",
        "                labels=labels\n",
        "            )\n",
        "            image = sample['image']\n",
        "            # Perbarui boxes dan labels DARI HASIL augmentasi (INI PERBAIKANNYA)\n",
        "            target['boxes'] = torch.tensor(sample['bboxes'], dtype=torch.float32) if len(sample['bboxes']) > 0 else torch.empty((0, 4))\n",
        "            target['labels'] = torch.tensor(sample['labels'], dtype=torch.int64) if len(sample['labels']) > 0 else torch.empty(0, dtype=torch.int64)\n",
        "        else:\n",
        "            # Jika tidak ada transformasi, konversi langsung ke tensor\n",
        "            target['boxes'] = torch.tensor(boxes, dtype=torch.float32)\n",
        "            target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch): return tuple(zip(*batch))\n",
        "\n",
        "print(\"‚úÖ Kelas Dataset ('datasets.py') berhasil didefinisikan.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "869dcb3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869dcb3a",
        "outputId": "c25cb084-bb15-4220-d0c4-5d04f5c5ea43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data di validation dataset: 325\n",
            "‚úÖ Berhasil membuat validation loader. Seharusnya masalah path sudah benar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n"
          ]
        }
      ],
      "source": [
        "# Jalankan ini di sel baru untuk diagnosis\n",
        "try:\n",
        "    debug_valid_dataset = CustomDataset(VALID_IMG, VALID_ANNOT, RESIZE_TO, RESIZE_TO, CLASSES, get_valid_transform())\n",
        "    debug_valid_loader = DataLoader(debug_valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    print(f\"Jumlah data di validation dataset: {len(debug_valid_dataset)}\")\n",
        "    if len(debug_valid_dataset) > 0:\n",
        "        print(\"‚úÖ Berhasil membuat validation loader. Seharusnya masalah path sudah benar.\")\n",
        "    else:\n",
        "        print(\"üî¥ Peringatan: Validation dataset kosong! Periksa isi folder validasi Anda.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Terjadi error saat membuat validation loader: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca3342bc",
      "metadata": {
        "id": "ca3342bc"
      },
      "outputs": [],
      "source": [
        "# --- Cell 6: model.py (Versi Final yang Benar) ---\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork\n",
        "\n",
        "def create_model(num_classes, variant='efficientnet_b0', min_size=640, max_size=640):\n",
        "\n",
        "    backbone_options = {\n",
        "        'efficientnet_b0': (torchvision.models.efficientnet_b0, [40, 80, 112, 192]),\n",
        "        'efficientnet_b1': (torchvision.models.efficientnet_b1, [40, 80, 112, 192]),\n",
        "        'efficientnet_b2': (torchvision.models.efficientnet_b2, [48, 88, 120, 208]),\n",
        "        'efficientnet_b3': (torchvision.models.efficientnet_b3, [48, 96, 136, 232]),\n",
        "        'efficientnet_b4': (torchvision.models.efficientnet_b4, [56, 112, 160, 272]),\n",
        "    }\n",
        "\n",
        "    if variant not in backbone_options:\n",
        "        raise ValueError(f\"Varian '{variant}' tidak tersedia. Pilih dari: {list(backbone_options.keys())}\")\n",
        "\n",
        "    model_function, in_channels_list = backbone_options[variant]\n",
        "    backbone_model = model_function(weights='DEFAULT')\n",
        "\n",
        "    return_layers = {\"features.3\": \"0\", \"features.4\": \"1\", \"features.5\": \"2\", \"features.6\": \"3\"}\n",
        "    body = create_feature_extractor(backbone_model, return_layers)\n",
        "\n",
        "    fpn = FeaturePyramidNetwork(in_channels_list=in_channels_list, out_channels=256)\n",
        "\n",
        "    backbone = torch.nn.Sequential(OrderedDict([(\"body\", body), (\"fpn\", fpn)]))\n",
        "    backbone.out_channels = 256\n",
        "\n",
        "    # Konfigurasi yang benar ada di sini\n",
        "    anchor_generator = AnchorGenerator(\n",
        "        sizes=((32,), (64,), (128,), (256,)), # Changed to 4 size tuples\n",
        "        aspect_ratios=((0.5, 1.0, 2.0),) * 4 # Changed to 4 aspect ratio tuples\n",
        "    )\n",
        "\n",
        "    model = FasterRCNN(backbone, num_classes=num_classes, rpn_anchor_generator=anchor_generator, min_size=min_size, max_size=max_size)\n",
        "\n",
        "    print(f\"‚úÖ Model Faster R-CNN dengan backbone {variant} berhasil dibuat (dengan AnchorGenerator yang benar).\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b320958",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b320958",
        "outputId": "ca0308a3-410a-4166-aa91-6740d2e4534d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 148MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model Faster R-CNN dengan backbone efficientnet_b0 berhasil dibuat (dengan AnchorGenerator yang benar).\n"
          ]
        }
      ],
      "source": [
        "# Di dalam sel pelatihan Anda\n",
        "# Ganti baris inisialisasi model menjadi seperti ini:\n",
        "model = create_model(NUM_CLASSES, variant='efficientnet_b0', min_size=RESIZE_TO, max_size=RESIZE_TO).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247bf84c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660,
          "referenced_widgets": [
            "f7e0b74efa9141db9a81b4c773241a7d",
            "7272561fd1f045b78a0cfa22b5a151c9",
            "51c4efc5f88e4375b7ad9d0664678798",
            "7e29715e298f483f88d253ce36be6b05",
            "9d8bf0d7719f483a80e9113076e602da",
            "328cb0e65a9049f88426d93cfcd0d5dd",
            "36353a076a5242b1af268a27e2d3b273",
            "c951636567b74e998f31a27097e4e6e0",
            "15257e00d0c94064843df5c184065036",
            "6e2f975759c147318f6d72ffb13f77fd",
            "3cc61267fff84d35b41210fafe99bab5"
          ]
        },
        "id": "247bf84c",
        "outputId": "1f9fb471-3c17-4eda-dc72-30a0bbd9b821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODE: Mencari Learning Rate Optimal...\n",
            "‚úÖ Model Faster R-CNN dengan backbone efficientnet_b0 berhasil dibuat (dengan AnchorGenerator yang benar).\n",
            "Menjalankan LR Range Test... Ini mungkin memakan beberapa menit.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7e0b74efa9141db9a81b4c773241a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 1.70E-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Perhitungan Selesai.\n",
            "Learning Rate yang disarankan (titik penurunan loss paling tajam) adalah: 0.00000170\n"
          ]
        }
      ],
      "source": [
        "# --- Ganti seluruh blok 'if FIND_LEARNING_RATE:' di Cell 7 dengan ini ---\n",
        "\n",
        "FIND_LEARNING_RATE = True # Ganti menjadi False setelah menemukan LR yang bagus\n",
        "\n",
        "if FIND_LEARNING_RATE:\n",
        "    # 1. Impor dan instal pustaka yang dibutuhkan\n",
        "    !pip install torch-lr-finder -q\n",
        "    import torch\n",
        "    from torch_lr_finder import LRFinder\n",
        "    import numpy as np\n",
        "\n",
        "    print(\"MODE: Mencari Learning Rate Optimal...\")\n",
        "\n",
        "    # 2. Buat kelas LRFinder khusus untuk model deteksi\n",
        "    # (Kode ini sudah benar, tidak perlu diubah)\n",
        "    class DetectionLRFinder(LRFinder):\n",
        "        def _train_batch(self, train_iter, accumulation_steps, non_blocking_transfer):\n",
        "            self.model.train()\n",
        "            total_loss = None\n",
        "            self.optimizer.zero_grad()\n",
        "            for i in range(accumulation_steps):\n",
        "                try:\n",
        "                    images, targets = next(train_iter)\n",
        "                except StopIteration:\n",
        "                    train_iter = iter(self.train_loader)\n",
        "                    images, targets = next(train_iter)\n",
        "                images = [img.to(self.device) for img in images]\n",
        "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "                loss_dict = self.model(images, targets)\n",
        "                loss = sum(l for l in loss_dict.values())\n",
        "                loss /= accumulation_steps\n",
        "                loss.backward()\n",
        "                if total_loss is None:\n",
        "                    total_loss = loss\n",
        "                else:\n",
        "                    total_loss += loss\n",
        "            self.optimizer.step()\n",
        "            return total_loss.item()\n",
        "\n",
        "    # 3. Inisialisasi model dan optimizer\n",
        "    model_finder = create_model(NUM_CLASSES).to(DEVICE)    # <-- PERBAIKAN 2: Mengubah num_classes menjadi NUM_CLASSES\n",
        "    optimizer_finder = torch.optim.RMSprop(model_finder.parameters(), lr=1e-7, weight_decay=0.0005)\n",
        "\n",
        "    # 4. Inisialisasi DataLoader\n",
        "    train_dataset_finder = CustomDataset(TRAIN_IMG, TRAIN_ANNOT, RESIZE_TO, RESIZE_TO, CLASSES, get_train_transform())\n",
        "    train_loader_finder = DataLoader(train_dataset_finder, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
        "\n",
        "    # 5. Jalankan LR Finder\n",
        "    lr_finder = DetectionLRFinder(model_finder, optimizer_finder, criterion=None, device=DEVICE)\n",
        "    print(\"Menjalankan LR Range Test... Ini mungkin memakan beberapa menit.\")\n",
        "    lr_finder.range_test(train_loader_finder, end_lr=1, num_iter=200, step_mode=\"exp\")\n",
        "\n",
        "    # 6. Plot hasilnya\n",
        "    lr_finder.plot()\n",
        "\n",
        "    # 7. Hitung dan cetak LR yang disarankan\n",
        "    lrs = lr_finder.history['lr']\n",
        "    losses = lr_finder.history['loss']\n",
        "    grads = np.gradient(losses)\n",
        "    min_grad_idx = np.argmin(grads)\n",
        "    suggested_lr = lrs[min_grad_idx]\n",
        "\n",
        "    print(f\"\\n‚úÖ Perhitungan Selesai.\")\n",
        "    print(f\"Learning Rate yang disarankan (titik penurunan loss paling tajam) adalah: {suggested_lr:.8f}\")\n",
        "\n",
        "    lr_finder.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003f77d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "003f77d5",
        "outputId": "58dec399-795b-48f3-af25-4d8a7d32f74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data latih: 1295 | Data validasi: 325\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model Faster R-CNN dengan backbone efficientnet_b0 berhasil dibuat (dengan AnchorGenerator yang benar).\n",
            "\n",
            "--- Epoch 1/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.4402: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:32<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.6320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.6100, mAP@0.5:0.95: 0.2863, Precision: 0.8367, F1: 0.8127\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.2863.pth\n",
            "\n",
            "--- Epoch 2/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.3347: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:32<00:00,  5.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.3760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  9.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.7996, mAP@0.5:0.95: 0.4198, Precision: 0.7839, F1: 0.7238\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.4198.pth\n",
            "\n",
            "--- Epoch 3/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.2164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.2706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.8700, mAP@0.5:0.95: 0.5246, Precision: 0.6385, F1: 0.5694\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.5246.pth\n",
            "\n",
            "--- Epoch 4/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1888: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.2125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.8964, mAP@0.5:0.95: 0.5749, Precision: 0.6847, F1: 0.6433\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.5749.pth\n",
            "\n",
            "--- Epoch 5/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9191, mAP@0.5:0.95: 0.6073, Precision: 0.4075, F1: 0.3481\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.6073.pth\n",
            "\n",
            "--- Epoch 6/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1615: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9255, mAP@0.5:0.95: 0.6260, Precision: 0.6688, F1: 0.6165\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.6260.pth\n",
            "\n",
            "--- Epoch 7/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1613: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9361, mAP@0.5:0.95: 0.6630, Precision: 0.7384, F1: 0.7259\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.6630.pth\n",
            "\n",
            "--- Epoch 8/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0896: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9384, mAP@0.5:0.95: 0.6766, Precision: 0.6537, F1: 0.6189\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.6766.pth\n",
            "\n",
            "--- Epoch 9/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1274: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9491, mAP@0.5:0.95: 0.6754, Precision: 0.6925, F1: 0.6393\n",
            "\n",
            "--- Epoch 10/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1447: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9612, mAP@0.5:0.95: 0.6930, Precision: 0.6680, F1: 0.6367\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.6930.pth\n",
            "\n",
            "--- Epoch 11/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9813, mAP@0.5:0.95: 0.7105, Precision: 0.7395, F1: 0.7036\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7105.pth\n",
            "\n",
            "--- Epoch 12/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.1267: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9702, mAP@0.5:0.95: 0.7124, Precision: 0.6772, F1: 0.6490\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7124.pth\n",
            "\n",
            "--- Epoch 13/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0973: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9852, mAP@0.5:0.95: 0.7366, Precision: 0.6933, F1: 0.6439\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7366.pth\n",
            "\n",
            "--- Epoch 14/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0778: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.1030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9641, mAP@0.5:0.95: 0.7290, Precision: 0.7592, F1: 0.7367\n",
            "\n",
            "--- Epoch 15/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0821: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.0994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9916, mAP@0.5:0.95: 0.7537, Precision: 0.7875, F1: 0.7691\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7537.pth\n",
            "\n",
            "--- Epoch 16/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0933: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.0967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9813, mAP@0.5:0.95: 0.7428, Precision: 0.7845, F1: 0.7685\n",
            "\n",
            "--- Epoch 17/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0979: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9883, mAP@0.5:0.95: 0.7579, Precision: 0.8152, F1: 0.7978\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7579.pth\n",
            "\n",
            "--- Epoch 18/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.0908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9898, mAP@0.5:0.95: 0.7649, Precision: 0.7660, F1: 0.7344\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7649.pth\n",
            "\n",
            "--- Epoch 19/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0888: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.0878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  9.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9844, mAP@0.5:0.95: 0.7663, Precision: 0.8335, F1: 0.8220\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7663.pth\n",
            "\n",
            "--- Epoch 20/20 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.0802: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:31<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss Pelatihan: 0.0863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00, 10.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP@0.5: 0.9971, mAP@0.5:0.95: 0.7800, Precision: 0.8132, F1: 0.7981\n",
            "\n",
            "Valid mAP meningkat. Menyimpan model ke outputs/best_model_mAP_0.7800.pth\n",
            "\n",
            "‚úÖ Pelatihan Selesai!\n"
          ]
        }
      ],
      "source": [
        "# --- Cell 7: train.py ---\n",
        "\n",
        "# Inisialisasi datasets dan loaders\n",
        "train_dataset = CustomDataset(TRAIN_IMG, TRAIN_ANNOT, RESIZE_TO, RESIZE_TO, CLASSES, get_train_transform())\n",
        "valid_dataset = CustomDataset(VALID_IMG, VALID_ANNOT, RESIZE_TO, RESIZE_TO, CLASSES, get_valid_transform())\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
        "print(f\"Data latih: {len(train_dataset)} | Data validasi: {len(valid_dataset)}\\n\")\n",
        "\n",
        "# Inisialisasi model dan optimizer\n",
        "model = create_model(NUM_CLASSES, min_size=RESIZE_TO, max_size=RESIZE_TO).to(DEVICE)\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=suggested_lr, alpha=0.99, weight_decay=0.0005)\n",
        "\n",
        "# Inisialisasi pelacak metrik\n",
        "train_loss_hist = Averager()\n",
        "map_metric = MeanAveragePrecision()\n",
        "save_best_model = SaveBestModel()\n",
        "metrics_data, map_50_list, map_95_list = [], [], []\n",
        "\n",
        "# Loop Pelatihan\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\n--- Epoch {epoch + 1}/{NUM_EPOCHS} ---\")\n",
        "    train_loss_hist.reset(); model.train()\n",
        "    prog_bar = tqdm(train_loader, total=len(train_loader))\n",
        "\n",
        "    # Fase Training\n",
        "    for images, targets in prog_bar:\n",
        "        images = [img.to(DEVICE) for img in images]\n",
        "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "        optimizer.zero_grad()\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        losses.backward(); optimizer.step()\n",
        "        train_loss_hist.send(losses.item())\n",
        "        prog_bar.set_description(f\"Loss: {losses.item():.4f}\")\n",
        "    print(f\"Loss Pelatihan: {train_loss_hist.value:.4f}\")\n",
        "\n",
        "    # Fase Validasi\n",
        "    model.eval(); map_metric.reset()\n",
        "    all_true_labels, all_pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(valid_loader, desc=\"Validating\"):\n",
        "            images = [img.to(DEVICE) for img in images]; outputs = model(images)\n",
        "            for i in range(len(images)):\n",
        "                true_labels, true_boxes = targets[i][\"labels\"].cpu(), targets[i][\"boxes\"].cpu()\n",
        "                pred_scores, pred_labels, pred_boxes = outputs[i][\"scores\"].cpu(), outputs[i][\"labels\"].cpu(), outputs[i][\"boxes\"].cpu()\n",
        "                mask = pred_scores > 0.5\n",
        "                map_metric.update([{\"boxes\": pred_boxes[mask], \"scores\": pred_scores[mask], \"labels\": pred_labels[mask]}],\n",
        "                                  [{\"boxes\": true_boxes, \"labels\": true_labels}])\n",
        "                all_true_labels.extend(true_labels.numpy())\n",
        "                all_pred_labels.extend(pred_labels[mask].numpy())\n",
        "\n",
        "    # Kalkulasi Metrik\n",
        "    map_result = map_metric.compute()\n",
        "    min_len = min(len(all_true_labels), len(all_pred_labels))\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels[:min_len], all_pred_labels[:min_len], average=\"weighted\", zero_division=0)\n",
        "    print(f\"mAP@0.5: {map_result['map_50']:.4f}, mAP@0.5:0.95: {map_result['map']:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "    # Simpan hasil\n",
        "    map_50_list.append(map_result['map_50'].item()); map_95_list.append(map_result['map'].item())\n",
        "    metrics_data.append({\"Epoch\": epoch+1, \"Train Loss\": train_loss_hist.value, \"mAP@0.5\": map_result['map_50'].item(), \"mAP@0.5:0.95\": map_result['map'].item(), \"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1})\n",
        "    train_losses = [e[\"Train Loss\"] for e in metrics_data]\n",
        "    save_loss_plot(OUT_DIR, train_losses); save_mAP(OUT_DIR, map_50_list, map_95_list)\n",
        "    save_best_model(model, map_result['map'].item(), epoch, OUT_DIR)\n",
        "\n",
        "# Simpan metrik ke Excel\n",
        "pd.DataFrame(metrics_data).to_excel(f\"{OUT_DIR}/all_metrics.xlsx\", index=False)\n",
        "print(\"\\n‚úÖ Pelatihan Selesai!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SEL BARU: EVALUASI PADA HOLD-OUT TEST SET ---\n",
        "\n",
        "# 1. Tentukan path ke test set Anda\n",
        "#    (Anda mungkin perlu membuat folder ini dari data asli Anda)\n",
        "TEST_IMG_DIR = os.path.join(OUTPUT_DIR, \"val\", \"Image\")\n",
        "TEST_ANNOT_DIR = os.path.join(OUTPUT_DIR, \"val\", \"Annotation\")\n",
        "\n",
        "# Pastikan folder ada\n",
        "if not os.path.exists(TEST_IMG_DIR):\n",
        "    print(f\"‚ùå Peringatan: Direktori Test Set '{TEST_IMG_DIR}' tidak ditemukan. Lewati evaluasi.\")\n",
        "else:\n",
        "    print(\"Memulai evaluasi pada Test Set...\")\n",
        "\n",
        "    # 2. Muat model terbaik yang sudah dilatih\n",
        "    # Temukan path model terbaik secara otomatis dari folder outputs\n",
        "    try:\n",
        "        best_model_path = sorted(glob.glob(f\"{OUT_DIR}/best_model_*.pth\"))[-1]\n",
        "        print(f\"Memuat model dari: {best_model_path}\")\n",
        "    except IndexError:\n",
        "        print(\"‚ùå Tidak dapat menemukan model 'best_model.pth'. Pastikan pelatihan sudah selesai.\")\n",
        "        best_model_path = None\n",
        "\n",
        "    if best_model_path:\n",
        "        model_test = create_model(NUM_CLASSES).to(DEVICE)\n",
        "        checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
        "        model_test.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model_test.eval() # Set model ke mode evaluasi\n",
        "\n",
        "        # 3. Buat DataLoader untuk test set\n",
        "        test_dataset = CustomDataset(TEST_IMG_DIR, TEST_ANNOT_DIR, RESIZE_TO, RESIZE_TO, CLASSES, get_valid_transform())\n",
        "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
        "\n",
        "        # 4. Inisialisasi metrik dan jalankan evaluasi\n",
        "        map_metric_test = MeanAveragePrecision()\n",
        "        with torch.no_grad():\n",
        "            for images, targets in tqdm(test_loader, desc=\"Testing\"):\n",
        "                images = [img.to(DEVICE) for img in images]\n",
        "                outputs = model_test(images)\n",
        "\n",
        "                # Pindahkan output ke CPU untuk evaluasi\n",
        "                targets_cpu = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
        "                outputs_cpu = [{k: v.cpu() for k, v in t.items()} for t in outputs]\n",
        "\n",
        "                map_metric_test.update(outputs_cpu, targets_cpu)\n",
        "\n",
        "        # 5. Hitung dan tampilkan hasil akhir\n",
        "        test_results = map_metric_test.compute()\n",
        "        print(\"\\n--- HASIL PADA TEST SET ---\")\n",
        "        print(f\"mAP@0.5: {test_results['map_50']:.4f}\")\n",
        "        print(f\"mAP@0.5:0.95: {test_results['map']:.4f}\")\n",
        "        print(f\"mAP (Large Objects): {test_results['map_large']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0-jDB1P3SX1",
        "outputId": "c6bb0930-53bf-4dca-ed0e-36ba57ce13dc"
      },
      "id": "R0-jDB1P3SX1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai evaluasi pada Test Set...\n",
            "Memuat model dari: outputs/best_model_mAP_0.7800.pth\n",
            "‚úÖ Model Faster R-CNN dengan backbone efficientnet_b0 berhasil dibuat (dengan AnchorGenerator yang benar).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:04<00:00,  9.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- HASIL PADA TEST SET ---\n",
            "mAP@0.5: 0.9971\n",
            "mAP@0.5:0.95: 0.7805\n",
            "mAP (Large Objects): 0.7810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "74Jffpu36Uh1"
      },
      "id": "74Jffpu36Uh1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f7e0b74efa9141db9a81b4c773241a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7272561fd1f045b78a0cfa22b5a151c9",
              "IPY_MODEL_51c4efc5f88e4375b7ad9d0664678798",
              "IPY_MODEL_7e29715e298f483f88d253ce36be6b05"
            ],
            "layout": "IPY_MODEL_9d8bf0d7719f483a80e9113076e602da"
          }
        },
        "7272561fd1f045b78a0cfa22b5a151c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328cb0e65a9049f88426d93cfcd0d5dd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_36353a076a5242b1af268a27e2d3b273",
            "value": "‚Äá54%"
          }
        },
        "51c4efc5f88e4375b7ad9d0664678798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c951636567b74e998f31a27097e4e6e0",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15257e00d0c94064843df5c184065036",
            "value": 108
          }
        },
        "7e29715e298f483f88d253ce36be6b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2f975759c147318f6d72ffb13f77fd",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cc61267fff84d35b41210fafe99bab5",
            "value": "‚Äá108/200‚Äá[00:24&lt;00:17,‚Äá‚Äá5.20it/s]"
          }
        },
        "9d8bf0d7719f483a80e9113076e602da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328cb0e65a9049f88426d93cfcd0d5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36353a076a5242b1af268a27e2d3b273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c951636567b74e998f31a27097e4e6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15257e00d0c94064843df5c184065036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e2f975759c147318f6d72ffb13f77fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc61267fff84d35b41210fafe99bab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}